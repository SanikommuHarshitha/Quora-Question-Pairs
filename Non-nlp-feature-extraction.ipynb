{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CORES = 10\n",
    "FREQ_UPPER_BOUND = 100\n",
    "NEIGHBOR_UPPER_BOUND = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**np.dstack is a numpy function which stacks arrays in sequence depth wise**\n",
    "\n",
    "**First, question1, question2 columns are combined in both train and test datasets and the resulting arrays are combined to form a list. Then the duplicates in the list are removed.**\n",
    "\n",
    "**reset_index() resets the index of the DataFrame, and use the default one instead**\n",
    "\n",
    "**to_dict() converts dataframe to dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question_hash(train_df, test_df):\n",
    "    train_qs = np.dstack([train_df[\"question1\"], train_df[\"question2\"]]).flatten()\n",
    "    test_qs = np.dstack([test_df[\"question1\"], test_df[\"question2\"]]).flatten()\n",
    "    all_qs = np.append(train_qs, test_qs)\n",
    "    all_qs = pd.DataFrame(all_qs)[0].drop_duplicates()\n",
    "    all_qs.reset_index(inplace=True, drop=True)\n",
    "    question_dict = pd.Series(all_qs.index.values, index=all_qs.values).to_dict()\n",
    "    return question_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dict functions need to resolve the target module in run-time, and then forward the call to that module. Calling HashDict directly overcomes this step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(df, hash_dict):\n",
    "    df[\"qid1\"] = df[\"question1\"].map(hash_dict)\n",
    "    df[\"qid2\"] = df[\"question2\"].map(hash_dict)\n",
    "    return df.drop([\"question1\", \"question2\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A k-core is a maximal subgraph that contains nodes of degree k or more.**\n",
    "\n",
    "**Initially, an undirected graph is generated. Then a column is passed as a node. Then edges are created using the list of columns from the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kcore_dict(df):\n",
    "    g = nx.Graph() #empty graph\n",
    "    g.add_nodes_from(df.qid1)\n",
    "    edges = list(df[[\"qid1\", \"qid2\"]].to_records(index=False))\n",
    "    g.add_edges_from(edges)\n",
    "    g.remove_edges_from(g.selfloop_edges())\n",
    "    df_output = pd.DataFrame(data=g.nodes(), columns=[\"qid\"])\n",
    "    df_output[\"kcore\"] = 0\n",
    "    for k in range(2, NB_CORES + 1):\n",
    "        ck = nx.k_core(g, k=k).nodes()\n",
    "        print(\"kcore\", k)\n",
    "        df_output.ix[df_output.qid.isin(ck), \"kcore\"] = k\n",
    "\n",
    "    return df_output.to_dict()[\"kcore\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating kcore features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kcore_features(df, kcore_dict):\n",
    "    df[\"kcore1\"] = df[\"qid1\"].apply(lambda x: kcore_dict[x])\n",
    "    df[\"kcore2\"] = df[\"qid2\"].apply(lambda x: kcore_dict[x])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**np.vstack returns stack arrays in sequence vertically.**\n",
    "\n",
    "**.T generates the transpose of the array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_minmax(df, col):\n",
    "    sorted_features = np.sort(np.vstack([df[col + \"1\"], df[col + \"2\"]]).T)\n",
    "    df[\"min_\" + col] = sorted_features[:, 0]\n",
    "    df[\"max_\" + col] = sorted_features[:, 1]\n",
    "    return df.drop([col + \"1\", col + \"2\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The defaultdict will simply create any items that you try to access (provided of course they do not exist yet).**\n",
    "\n",
    "**The zip() function take iterables (can be zero or more), makes iterator that aggregates elements based on the iterables passed, and returns an iterator of tuples.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(train_df, test_df):\n",
    "    neighbors = defaultdict(set)\n",
    "    for df in [train_df, test_df]:\n",
    "        for q1, q2 in zip(df[\"qid1\"], df[\"qid2\"]):\n",
    "            neighbors[q1].add(q2)\n",
    "            neighbors[q2].add(q1)\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate common neighbor ratio and common neighbor count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_features(df, neighbors):\n",
    "    common_nc = df.apply(lambda x: len(neighbors[x.qid1].intersection(neighbors[x.qid2])), axis=1)\n",
    "    min_nc = df.apply(lambda x: min(len(neighbors[x.qid1]), len(neighbors[x.qid2])), axis=1)\n",
    "    df[\"common_neighbor_ratio\"] = common_nc / min_nc\n",
    "    df[\"common_neighbor_count\"] = common_nc.apply(lambda x: min(x, NEIGHBOR_UPPER_BOUND))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_features(df, frequency_map):\n",
    "    df[\"freq1\"] = df[\"qid1\"].map(lambda x: min(frequency_map[x], FREQ_UPPER_BOUND))\n",
    "    df[\"freq2\"] = df[\"qid2\"].map(lambda x: min(frequency_map[x], FREQ_UPPER_BOUND))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Load data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Passing the datasets into functions as parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hashing the questions...\")\n",
    "question_dict = create_question_hash(train_df, test_df)\n",
    "train_df = get_hash(train_df, question_dict)\n",
    "test_df = get_hash(test_df, question_dict)\n",
    "print(\"Number of unique questions:\", len(question_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating kcore features...\n",
      "kcore 2\n",
      "kcore 3\n",
      "kcore 4\n",
      "kcore 5\n",
      "kcore 6\n",
      "kcore 7\n",
      "kcore 8\n",
      "kcore 9\n",
      "kcore 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating kcore features...\")\n",
    "all_df = pd.concat([train_df, test_df])\n",
    "kcore_dict = get_kcore_dict(all_df)\n",
    "train_df = get_kcore_features(train_df, kcore_dict)\n",
    "test_df = get_kcore_features(test_df, kcore_dict)\n",
    "train_df = convert_to_minmax(train_df, \"kcore\")\n",
    "test_df = convert_to_minmax(test_df, \"kcore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating common neighbor features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating common neighbor features...\")\n",
    "neighbors = get_neighbors(train_df, test_df)\n",
    "train_df = get_neighbor_features(train_df, neighbors)\n",
    "test_df = get_neighbor_features(test_df, neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating frequency features...\n"
     ]
    }
   ],
   "source": [
    "print(\"Calculating frequency features...\")\n",
    "frequency_map = dict(zip(*np.unique(np.vstack((all_df[\"qid1\"], all_df[\"qid2\"])), return_counts=True)))\n",
    "train_df = get_freq_features(train_df, frequency_map)\n",
    "test_df = get_freq_features(test_df, frequency_map)\n",
    "train_df = convert_to_minmax(train_df, \"freq\")\n",
    "test_df = convert_to_minmax(test_df, \"freq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the generated features and values are passed into the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"min_kcore\", \"max_kcore\", \"common_neighbor_count\", \"common_neighbor_ratio\", \"min_freq\", \"max_freq\"]\n",
    "train_df.loc[:, cols].to_csv(\"non_nlp_features_train.csv\", index=False)\n",
    "test_df.loc[:, cols].to_csv(\"non_nlp_features_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
